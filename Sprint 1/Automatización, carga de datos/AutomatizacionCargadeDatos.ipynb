{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para automatizar la carga de nuevos datos a nuestra base de datos SQL Server, implementamos un proceso:\n",
    "\n",
    "*Configuración del flujo de ingesta de datos*\n",
    "\n",
    "Estructura de carpetas: Organizamos los archivos CSV de nuevos datos en una carpeta específica que el sistema monitoree regularmente.\n",
    "*/data/new_data* para los archivos CSV nuevos.\n",
    "*/data/processed* para los archivos ya cargados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Programación de Tareas (Task Scheduler)*\n",
    "\n",
    "Windows Task Scheduler : Configuramos una tarea programada que se ejecute a intervalos regulares (diariamente, semanalmente, según necesidad).\n",
    "Utilizando script en Python, programandolo con Task Scheduler para ejecutar la carga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el siguiente codigo para copiar y pegar en el siguiente archivo que lo llamamos \"script.py\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "class FileHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        # Llama al script de carga cuando se detecta un nuevo archivo CSV\n",
    "        if event.src_path.endswith('.csv'):\n",
    "            print(f'Nuevo archivo encontrado: {event.src_path}')\n",
    "            cargar_datos_a_sql(event.src_path)\n",
    "\n",
    "def cargar_datos_a_sql(csv_file):\n",
    "    # Configuración de la conexión a SQL Server usando SQLAlchemy\n",
    "    server = r'DESKTOP-5Q8KF0G\\SQLEXPRESS'  # Cambia por tu servidor SQL\n",
    "    database = 'PremiumDrinks' \n",
    "    connection_string = f'mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "    \n",
    "    conn = None  # Inicializamos la variable conn fuera del try\n",
    "\n",
    "    try:\n",
    "        engine = create_engine(connection_string)\n",
    "        conn = engine.connect()\n",
    "\n",
    "        # Ruta para mover archivos procesados\n",
    "        processed_folder = r'C:\\Users\\Mati puto\\Downloads\\data set pf\\data set limpios(compañeras)\\limpios para sql\\data\\processed'\n",
    "\n",
    "\n",
    "        # Diccionario que mapea nombres de archivo a tablas\n",
    "        file_to_table_map = {\n",
    "            'new_2017PurchasePricesDec.csv': 'PrecioCompra',\n",
    "            'new_BegInvFINAL12312016.csv': 'InventarioInicial',\n",
    "            'new_EndInvFINAL12312016.csv': 'InventarioFinal',\n",
    "            'new_InvoicePurchases12312016.csv': 'FacturasCompras2016',\n",
    "            'new_PurchasesFINAL12312016.csv': 'Compras2016',\n",
    "            'new_SalesFINAL12312016.csv': 'Ventas2016'\n",
    "        }\n",
    "\n",
    "        # Leer el archivo CSV en un DataFrame de pandas\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Determinar la tabla de destino\n",
    "        base_filename = os.path.basename(csv_file)\n",
    "        table_name = file_to_table_map.get(base_filename)\n",
    "        \n",
    "        if not table_name:\n",
    "            print(f\"No hay una tabla mapeada para el archivo {base_filename}.\")\n",
    "            return\n",
    "\n",
    "        # Cargar el DataFrame a SQL Server\n",
    "        df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "        print(f\"Datos cargados desde {csv_file} a la tabla {table_name}.\")\n",
    "        \n",
    "        # Mover archivo procesado a la carpeta de procesados\n",
    "        os.rename(csv_file, os.path.join(processed_folder, base_filename))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error procesando {csv_file}: {e}\")\n",
    "    finally:\n",
    "        if conn:  # Verifica si conn fue asignado antes de cerrar\n",
    "            conn.close()\n",
    "            print(\"Conexión cerrada.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    event_handler = FileHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path=r'C:\\Users\\Mati puto\\Downloads\\data set pf\\data set limpios(compañeras)\\limpios para sql\\data\\new_data', recursive=False)\n",
    "    observer.start()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Automatización del flujo de carga*\n",
    "\n",
    "Monitoreo y carga automática de archivos nuevos: Implementamos un mecanismo que monitoree la carpeta /data/new_data y que dispare el script cuando se detecten nuevos archivos.\n",
    "Usamos librerías como watchdog para monitorear la carpeta y ejecutar el script de carga cuando aparezcan nuevos archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para automatizar la carga de nuevos datos a nuestra base de datos SQL Server, implementamos un proceso:\n",
    "\n",
    "*Configuración del flujo de ingesta de datos*\n",
    "\n",
    "Estructura de carpetas: Organizamos los archivos CSV de nuevos datos en una carpeta específica que el sistema monitoree regularmente.\n",
    "*/data/new_data* para los archivos CSV nuevos.\n",
    "*/data/processed* para los archivos ya cargados.\n",
    "\n",
    "*Programación de Tareas (Task Scheduler)*\n",
    "\n",
    "Windows Task Scheduler : Configuramos una tarea programada que se ejecute a intervalos regulares (diariamente, semanalmente, según necesidad).\n",
    "Utilizando script en Python, programandolo con Task Scheduler para ejecutar la carga.\n",
    "\n",
    "*Automatización del flujo de carga*\n",
    "\n",
    "Monitoreo y carga automática de archivos nuevos: Implementamos un mecanismo que monitoree la carpeta */data/new_data* y que dispare el script cuando se detecten nuevos archivos.\n",
    "En Python, usamos la libreria watchdog para monitorear la carpeta y ejecutar el script de carga cuando aparezcan nuevos archivos\n",
    "\n",
    "*Mover los archivos procesados*\n",
    "Después de procesar un archivo , se mueve el archivo CSV de */data/new_data* a */data/processed* para mantener un registro claro de lo que ya se ha cargado.\n",
    "Esto lo logramos mediante un script de Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
